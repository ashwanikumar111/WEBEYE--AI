# -*- coding: utf-8 -*-
"""Untitled22.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1unDjQVXnMN4jqZSzo53z32k1n-BwJ6Xz
"""

#Image classification code:
import cv2
import pandas as pd
import numpy as np

    # Load color names and RGB values from CSV file
index = ["color", "color_name", "hex", "R", "G", "B"]
csv = pd.read_csv('colors.csv', names=index, header=None)

    # Load SSD MobileNet V3 model for object detection
config_file = "ssd_mobilenet_v3_large_coco_2020_01_14.pbtxt"
frozen_model = "frozen_inference_graph.pb"
model = cv2.dnn_DetectionModel(frozen_model, config_file)

    # Load class labels for object detection
classLabels = []
file_name = "labels.txt"
with open(file_name, "rt") as fpt:
  classLabels = fpt.read().rstrip("\n").split("\n")

    # Global variables for color detection and region selection
clicked = False
r = g = b = x_pos = y_pos = 0
selected_region = []

    # Conversion factors (for example purposes, you need to measure and calculate these values)
ref_width_cm = 10  # Width of the reference object in centimeters
ref_height_cm = 5  # Height of the reference object in centimeters
ref_width_px = 100  # Width of the reference object in pixels
ref_height_px = 50  # Height of the reference object in pixels

    # Function to calculate minimum distance from all colors and get the most matching color
def get_color_name(R, G, B):
 minimum = 10000
color_accuracy = 0.0
color_name = ""
for i in range(len(csv)):
  d = abs(R - int(csv.loc[i, "R"])) + abs(G - int(csv.loc[i, "G"])) + abs(B - int(csv.loc[i, "B"]))

if d <= minimum:
   minimum = d
   color_name = csv.loc[i, "color_name"]
   color_accuracy = 1 - (minimum / (255 * 3))  # Calculate accuracy as a ratio between 0 and 1
   return color_name, color_accuracy

    # Function to handle mouse events for color detection and region selection
def draw_function(event, x, y, flags, param):
  global b, g, r, x_pos, y_pos, clicked, selected_region

if event == cv2.EVENT_LBUTTONDBLCLK:
            clicked = True
            x_pos = x
            y_pos = y
            b, g, r = img[y, x]
            b = int(b)
            g = int(g)
            r = int(r)
            selected_region.clear()

elif event == cv2.EVENT_LBUTTONDOWN:
            clicked = False
            selected_region.clear()
            selected_region.append((x, y))

elif event == cv2.EVENT_MOUSEMOVE:
            if flags & cv2.EVENT_FLAG_LBUTTON:
                if len(selected_region) == 1:
                    selected_region.append((x, y))
                elif len(selected_region) == 2:
                    selected_region[1] = (x, y)

    # Set up OpenCV window and mouse event callback
cv2.namedWindow('image')
cv2.setMouseCallback('image', draw_function)

    # Load the image
img_path = "sam.jpg"
img = cv2.imread(img_path)

    # Perform object detection on the image
model.setInputSize(320, 320)
model.setInputScale(1.0/127.5)
model.setInputMean((127.5, 127.5, 127.5))
model.setInputSwapRB(True)
ClassIndex, confidence, bbox = model.detect(img, confThreshold=0.5)

    # Display the image with detected objects and their confidence scores
for ClassInd, conf, boxes in zip(ClassIndex.flatten(), confidence.flatten(), bbox):
        x, y, w, h = boxes
        cv2.rectangle(img, (x, y), (x+w, y+h), (255, 0, 0), 2)
        accuracy = f"{conf*100:.0f}%"  # Format the accuracy as a percentage without decimal points
        label = f"{classLabels[ClassInd-1]}: {accuracy}"
        cv2.putText(img, label, (x, y-10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 0), 2)
        # Calculate dimensions of detected object
        obj_width_cm = w * (ref_width_cm / ref_width_px)
        obj_height_cm = h * (ref_height_cm / ref_height_px)
        obj_text = f"Width: {obj_width_cm:.2f} cm, Height: {obj_height_cm:.2f} cm"
        cv2.putText(img, obj_text, (x, y - 30), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 0), 2)

    # Main loop for displaying the image and handling mouse events
while True:
        display_img = img.copy()

        if clicked:
            # Get color name and RGB values of the clicked point
            color_name, color_accuracy = get_color_name(r, g, b)
            text = f"Color: {color_name}  R={r} G={g} B={b} Accuracy: {color_accuracy*100:.0f}%"
            # Draw rectangle filled with the color
            cv2.rectangle(display_img, (x_pos - 20, y_pos - 20), (x_pos + 20, y_pos + 20), (b, g, r), -1)
            cv2.putText(display_img, text, (x_pos, y_pos), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 255), 2)

        if len(selected_region) == 2:
            cv2.rectangle(display_img, selected_region[0], selected_region[1], (0, 255, 0), 2)

            # Calculate dimensions of selected region
            x1, y1 = selected_region[0]
            x2, y2 = selected_region[1]
            selected_region_width_cm = abs(x2 - x1) * (ref_width_cm / ref_width_px)
            selected_region_height_cm = abs(y2 - y1) * (ref_height_cm / ref_height_px)
            region_text = f"Width: {selected_region_width_cm:.2f} cm, Height: {selected_region_height_cm:.2f} cm"
            cv2.putText(display_img, region_text, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)

        cv2.imshow("image", display_img)

        # Break the loop when user hits 'esc' key
        key = cv2.waitKey(1)
        if key == 27:
            break

cv2.destroyAllWindows()

#Video Classification code:
import cv2
import pandas as pd
import numpy as np

# Load color names and RGB values from CSV file
index = ["color", "color_name", "hex", "R", "G", "B"]
csv = pd.read_csv('colors.csv', names=index, header=None)

# Load SSD MobileNet V3 model for object detection
config_file = "ssd_mobilenet_v3_large_coco_2020_01_14.pbtxt"
frozen_model = "frozen_inference_graph.pb"
model = cv2.dnn_DetectionModel(frozen_model, config_file)

# Load class labels for object detection
classLabels = []
file_name = "labels.txt"
with open(file_name, "rt") as fpt:
    classLabels = fpt.read().rstrip("\n").split("\n")

# Global variables for color detection and region selection
clicked = False
r = g = b = x_pos = y_pos = 0
selected_region = []

# Function to calculate minimum distance from all colors and get the most matching color
def get_color_name(R, G, B):
    minimum = 10000
    color_accuracy = 0.0
    color_name = ""
    for i in range(len(csv)):
        d = abs(R - int(csv.loc[i, "R"])) + abs(G - int(csv.loc[i, "G"])) + abs(B - int(csv.loc[i, "B"]))

        if d <= minimum:
            minimum = d
            color_name = csv.loc[i, "color_name"]
            color_accuracy = 1 - (minimum / (255 * 3))  # Calculate accuracy as a ratio between 0 and 1
    return color_name, color_accuracy

# Function to handle mouse events for color detection and region selection
def draw_function(event, x, y, flags, param):
    global b, g, r, x_pos, y_pos, clicked, selected_region

    if event == cv2.EVENT_LBUTTONDBLCLK:
        clicked = True
        x_pos = x
        y_pos = y
        b, g, r = frame[y, x]
        b = int(b)
        g = int(g)
        r = int(r)
        selected_region.clear()

    elif event == cv2.EVENT_LBUTTONDOWN:
        clicked = False
        selected_region.clear()
        selected_region.append((x, y))

    elif event == cv2.EVENT_MOUSEMOVE:
        if flags & cv2.EVENT_FLAG_LBUTTON:
            if len(selected_region) == 1:
                selected_region.append((x, y))
            elif len(selected_region) == 2:
                selected_region[1] = (x, y)

# Set up OpenCV window and mouse event callback
cv2.namedWindow('video')
cv2.setMouseCallback('video', draw_function)

# Open video capture device
cap = cv2.VideoCapture('trafic.mp4')

while True:
    ret, frame = cap.read()
    if not ret:
        break

    # Perform object detection on the frame
    model.setInputSize(320, 320)
    model.setInputScale(1.0/127.5)
    model.setInputMean((127.5, 127.5, 127.5))
    model.setInputSwapRB(True)
    ClassIndex, confidence, bbox = model.detect(frame, confThreshold=0.5)

    # Display the frame with detected objects and their confidence scores
    for ClassInd, conf, boxes in zip(ClassIndex.flatten(), confidence.flatten(), bbox):
        x, y, w, h = boxes
        cv2.rectangle(frame, (x, y), (x+w, y+h), (255, 0, 0), 2)
        accuracy = f"{conf*100:.0f}%"  # Format the accuracy as a percentage without decimal points
        label = f"{classLabels[ClassInd-1]}: {accuracy}"
        cv2.putText(frame, label, (x, y-10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 0), 2)

    if clicked:
        # Get color name and RGB values of the clicked point
        color_name, color_accuracy = get_color_name(r, g, b)
        text = f"Color: {color_name}  R={r} G={g} B={b} Accuracy: {color_accuracy*100:.0f}%"
        # Draw rectangle filled with the color
        cv2.rectangle(frame, (x_pos - 20, y_pos - 20), (x_pos + 20, y_pos + 20), (b, g, r), -1)
        cv2.putText(frame, text, (x_pos, y_pos), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 255), 2)

    if len(selected_region) == 2:
        cv2.rectangle(frame, selected_region[0], selected_region[1], (0, 255, 0), 2)

    cv2.imshow("video", frame)

    # Break the loop when user hits 'esc' key
    key = cv2.waitKey(1)
    if key == 27:
        break

cap.release()
cv2.destroyAllWindows()

#Live Camera classification code:
import cv2
import pandas as pd
import numpy as np

# Load color names and RGB values from CSV file
index = ["color", "color_name", "hex", "R", "G", "B"]
csv = pd.read_csv('colors.csv', names=index, header=None)

# Load SSD MobileNet V3 model for object detection
config_file = "ssd_mobilenet_v3_large_coco_2020_01_14.pbtxt"
frozen_model = "frozen_inference_graph.pb"
model = cv2.dnn_DetectionModel(frozen_model, config_file)

# Load class labels for object detection
classLabels = []
file_name = "labels.txt"
with open(file_name, "rt") as fpt:
    classLabels = fpt.read().rstrip("\n").split("\n")

# Global variables for color detection and region selection
clicked = False
r = g = b = x_pos = y_pos = 0
selected_region = []

# Conversion factors (for example purposes, you need to measure and calculate these values)
ref_width_cm = 10  # Width of the reference object in centimeters
ref_height_cm = 5  # Height of the reference object in centimeters
ref_width_px = 100  # Width of the reference object in pixels
ref_height_px = 50  # Height of the reference object in pixels

# Function to calculate minimum distance from all colors and get the most matching color
def get_color_name(R, G, B):
    minimum = 10000
    color_accuracy = 0.0
    color_name = ""
    for i in range(len(csv)):
        d = abs(R - int(csv.loc[i, "R"])) + abs(G - int(csv.loc[i, "G"])) + abs(B - int(csv.loc[i, "B"]))

        if d <= minimum:
            minimum = d
            color_name = csv.loc[i, "color_name"]
            color_accuracy = 1 - (minimum / (255 * 3))  # Calculate accuracy as a ratio between 0 and 1
    return color_name, color_accuracy

# Function to handle mouse events for color detection and region selection
def draw_function(event, x, y, flags, param):
    global b, g, r, x_pos, y_pos, clicked, selected_region

    if event == cv2.EVENT_LBUTTONDBLCLK:
        clicked = True
        x_pos = x
        y_pos = y
        b, g, r = frame[y, x]
        b = int(b)
        g = int(g)
        r = int(r)
        selected_region.clear()

    elif event == cv2.EVENT_LBUTTONDOWN:
        clicked = False
        selected_region.clear()
        selected_region.append((x, y))

    elif event == cv2.EVENT_MOUSEMOVE:
        if flags & cv2.EVENT_FLAG_LBUTTON:
            if len(selected_region) == 1:
                selected_region.append((x, y))
            elif len(selected_region) == 2:
                selected_region[1] = (x, y)

# Set up OpenCV window and mouse event callback
cv2.namedWindow('video')
cv2.setMouseCallback('video', draw_function)

# Open video capture device (you can also use a file instead of a camera)
cap = cv2.VideoCapture(0)  # Change to the appropriate video source if using a file

while True:
    ret, frame = cap.read()
    if not ret:
        break

    # Perform object detection on the frame
    model.setInputSize(320, 320)
    model.setInputScale(1.0/127.5)
    model.setInputMean((127.5, 127.5, 127.5))
    model.setInputSwapRB(True)
    ClassIndex, confidence, bbox = model.detect(frame, confThreshold=0.5)

    # Display the frame with detected objects and their confidence scores
    if isinstance(ClassIndex, tuple) and isinstance(confidence, tuple) and isinstance(bbox, tuple):
        ClassIndex = ClassIndex[0]
        confidence = confidence[0]
        bbox = bbox[0]

    for ClassInd, conf, boxes in zip(ClassIndex, confidence, bbox):
        x, y, w, h = boxes
        cv2.rectangle(frame, (x, y), (x+w, y+h), (255, 0, 0), 2)
        accuracy = f"{conf*100:.0f}%"  # Format the accuracy as a percentage without decimal points
        label = ""
        if ClassInd - 1 < len(classLabels):
            label = f"{classLabels[ClassInd-1]}: {accuracy}"
        else:
            label = "Unknown"
        cv2.putText(frame, label, (x, y-10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 0), 2)
        # Calculate dimensions of detected object
        obj_width_cm = w * (ref_width_cm / ref_width_px)
        obj_height_cm = h * (ref_height_cm / ref_height_px)
        obj_text = f"Width: {obj_width_cm:.2f} cm, Height: {obj_height_cm:.2f} cm"
        cv2.putText(frame, obj_text, (x, y - 30), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 0), 2)

    if clicked:
        # Get color name and RGB values of the clicked point
        color_name, color_accuracy = get_color_name(r, g, b)
        text = f"Color: {color_name}  R={r} G={g} B={b} Accuracy: {color_accuracy*100:.0f}%"
        # Draw rectangle filled with the color
        cv2.rectangle(frame, (x_pos - 20, y_pos - 20), (x_pos + 20, y_pos + 20), (b, g, r), -1)
        cv2.putText(frame, text, (x_pos, y_pos), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 255), 2)

    if len(selected_region) == 2:
        cv2.rectangle(frame, selected_region[0], selected_region[1], (0, 255, 0), 2)

        # Calculate dimensions of selected region
        x1, y1 = selected_region[0]
        x2, y2 = selected_region[1]
        selected_region_width_cm = abs(x2 - x1) * (ref_width_cm / ref_width_px)
        selected_region_height_cm = abs(y2 - y1) * (ref_height_cm / ref_height_px)
        region_text = f"Width: {selected_region_width_cm:.2f} cm, Height: {selected_region_height_cm:.2f} cm"
        cv2.putText(frame, region_text, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)

    cv2.imshow("video", frame)

    # Break the loop when user hits 'esc' key
    key = cv2.waitKey(1)
    if key == 27:
        break

cap.release()
cv2.destroyAllWindows()